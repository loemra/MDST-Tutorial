{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoint 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reminder: \n",
    "\n",
    "- You are being evaluated for compeletion and effort in this checkpoint. \n",
    "- Avoid manual labor / hard coding as much as possible, everything we've taught you so far are meant to simplify and automate your process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be working with the same `states_edu.csv` that you should already be familiar with from the tutorial.\n",
    "\n",
    "We investigated Grade 8 reading score in the tutorial. For this checkpoint, you are asked to investigate another test. Here's an overview:\n",
    "\n",
    "* Choose a specific response variable to focus on\n",
    ">Grade 4 Math, Grade 4 Reading, Grade 8 Math\n",
    "* Pick or create features to use\n",
    ">Will all the features be useful in predicting test score? Are some more important than others? Should you standardize, bin, or scale the data?\n",
    "* Explore the data as it relates to that test\n",
    ">Create at least 2 visualizations (graphs), each with a caption describing the graph and what it tells us about the data\n",
    "* Create training and testing data\n",
    ">Do you want to train on all the data? Only data from the last 10 years? Only Michigan data?\n",
    "* Train a ML model to predict outcome \n",
    ">Define what you want to predict, and pick a model in sklearn to use (see sklearn <a href=\"https://scikit-learn.org/stable/modules/linear_model.html\">regressors</a>.\n",
    "* Summarize your findings\n",
    ">Write a 1 paragraph summary of what you did and make a recommendation about if and how student performance can be predicted\n",
    "\n",
    "Include comments throughout your code! Every cleanup and preprocessing task should be documented.\n",
    "\n",
    "Of course, if you're finding this assignment interesting (and we really hope you do!), you are welcome to do more than the requirements! For example, you may want to see if expenditure affects 4th graders more than 8th graders. Maybe you want to look into the extended version of this dataset and see how factors like sex and race are involved. You can include all your work in this notebook when you turn it in -- just always make sure you explain what you did and interpret your results. Good luck!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Data Cleanup </h2>\n",
    "\n",
    "Import `numpy`, `pandas`, and `matplotlib`.\n",
    "\n",
    "(Feel free to import other libraries!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in the \"states_edu.csv\" dataset and take a look at the head of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRIMARY_KEY</th>\n",
       "      <th>STATE</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>ENROLL</th>\n",
       "      <th>TOTAL_REVENUE</th>\n",
       "      <th>FEDERAL_REVENUE</th>\n",
       "      <th>STATE_REVENUE</th>\n",
       "      <th>LOCAL_REVENUE</th>\n",
       "      <th>TOTAL_EXPENDITURE</th>\n",
       "      <th>INSTRUCTION_EXPENDITURE</th>\n",
       "      <th>...</th>\n",
       "      <th>GRADES_4_G</th>\n",
       "      <th>GRADES_8_G</th>\n",
       "      <th>GRADES_12_G</th>\n",
       "      <th>GRADES_1_8_G</th>\n",
       "      <th>GRADES_9_12_G</th>\n",
       "      <th>GRADES_ALL_G</th>\n",
       "      <th>AVG_MATH_4_SCORE</th>\n",
       "      <th>AVG_MATH_8_SCORE</th>\n",
       "      <th>AVG_READING_4_SCORE</th>\n",
       "      <th>AVG_READING_8_SCORE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1992_ALABAMA</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>1992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2678885.0</td>\n",
       "      <td>304177.0</td>\n",
       "      <td>1659028.0</td>\n",
       "      <td>715680.0</td>\n",
       "      <td>2653798.0</td>\n",
       "      <td>1481703.0</td>\n",
       "      <td>...</td>\n",
       "      <td>57948.0</td>\n",
       "      <td>58025.0</td>\n",
       "      <td>41167.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>731634.0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1992_ALASKA</td>\n",
       "      <td>ALASKA</td>\n",
       "      <td>1992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1049591.0</td>\n",
       "      <td>106780.0</td>\n",
       "      <td>720711.0</td>\n",
       "      <td>222100.0</td>\n",
       "      <td>972488.0</td>\n",
       "      <td>498362.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9748.0</td>\n",
       "      <td>8789.0</td>\n",
       "      <td>6714.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>122487.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1992_ARIZONA</td>\n",
       "      <td>ARIZONA</td>\n",
       "      <td>1992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3258079.0</td>\n",
       "      <td>297888.0</td>\n",
       "      <td>1369815.0</td>\n",
       "      <td>1590376.0</td>\n",
       "      <td>3401580.0</td>\n",
       "      <td>1435908.0</td>\n",
       "      <td>...</td>\n",
       "      <td>55433.0</td>\n",
       "      <td>49081.0</td>\n",
       "      <td>37410.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>673477.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1992_ARKANSAS</td>\n",
       "      <td>ARKANSAS</td>\n",
       "      <td>1992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1711959.0</td>\n",
       "      <td>178571.0</td>\n",
       "      <td>958785.0</td>\n",
       "      <td>574603.0</td>\n",
       "      <td>1743022.0</td>\n",
       "      <td>964323.0</td>\n",
       "      <td>...</td>\n",
       "      <td>34632.0</td>\n",
       "      <td>36011.0</td>\n",
       "      <td>27651.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>441490.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1992_CALIFORNIA</td>\n",
       "      <td>CALIFORNIA</td>\n",
       "      <td>1992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26260025.0</td>\n",
       "      <td>2072470.0</td>\n",
       "      <td>16546514.0</td>\n",
       "      <td>7641041.0</td>\n",
       "      <td>27138832.0</td>\n",
       "      <td>14358922.0</td>\n",
       "      <td>...</td>\n",
       "      <td>418418.0</td>\n",
       "      <td>363296.0</td>\n",
       "      <td>270675.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5254844.0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>261.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       PRIMARY_KEY       STATE  YEAR  ENROLL  TOTAL_REVENUE  FEDERAL_REVENUE  \\\n",
       "0     1992_ALABAMA     ALABAMA  1992     NaN      2678885.0         304177.0   \n",
       "1      1992_ALASKA      ALASKA  1992     NaN      1049591.0         106780.0   \n",
       "2     1992_ARIZONA     ARIZONA  1992     NaN      3258079.0         297888.0   \n",
       "3    1992_ARKANSAS    ARKANSAS  1992     NaN      1711959.0         178571.0   \n",
       "4  1992_CALIFORNIA  CALIFORNIA  1992     NaN     26260025.0        2072470.0   \n",
       "\n",
       "   STATE_REVENUE  LOCAL_REVENUE  TOTAL_EXPENDITURE  INSTRUCTION_EXPENDITURE  \\\n",
       "0      1659028.0       715680.0          2653798.0                1481703.0   \n",
       "1       720711.0       222100.0           972488.0                 498362.0   \n",
       "2      1369815.0      1590376.0          3401580.0                1435908.0   \n",
       "3       958785.0       574603.0          1743022.0                 964323.0   \n",
       "4     16546514.0      7641041.0         27138832.0               14358922.0   \n",
       "\n",
       "   ...  GRADES_4_G  GRADES_8_G  GRADES_12_G  GRADES_1_8_G  GRADES_9_12_G  \\\n",
       "0  ...     57948.0     58025.0      41167.0           NaN            NaN   \n",
       "1  ...      9748.0      8789.0       6714.0           NaN            NaN   \n",
       "2  ...     55433.0     49081.0      37410.0           NaN            NaN   \n",
       "3  ...     34632.0     36011.0      27651.0           NaN            NaN   \n",
       "4  ...    418418.0    363296.0     270675.0           NaN            NaN   \n",
       "\n",
       "   GRADES_ALL_G  AVG_MATH_4_SCORE  AVG_MATH_8_SCORE  AVG_READING_4_SCORE  \\\n",
       "0      731634.0             208.0             252.0                207.0   \n",
       "1      122487.0               NaN               NaN                  NaN   \n",
       "2      673477.0             215.0             265.0                209.0   \n",
       "3      441490.0             210.0             256.0                211.0   \n",
       "4     5254844.0             208.0             261.0                202.0   \n",
       "\n",
       "   AVG_READING_8_SCORE  \n",
       "0                  NaN  \n",
       "1                  NaN  \n",
       "2                  NaN  \n",
       "3                  NaN  \n",
       "4                  NaN  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/states_edu.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should always familiarize yourself with what each column in the dataframe represents. Read about the states_edu dataset here: https://www.kaggle.com/noriuk/us-education-datasets-unification-project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this space to rename columns, deal with missing data, etc. _(optional)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sw/ljh17lbj49g6lk45vz7n14t40000gn/T/ipykernel_77489/4123567192.py:21: FutureWarning: reindexing with a non-unique Index is deprecated and will raise in a future version.\n",
      "  t['AVG_MATH_8_SCORE'] = s_m[t['STATE']]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reindex on an axis with duplicate labels",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[75], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m s_m \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mgroupby([\u001b[39m'\u001b[39m\u001b[39mSTATE\u001b[39m\u001b[39m'\u001b[39m])\u001b[39m.\u001b[39mAVG_MATH_8_SCORE\u001b[39m.\u001b[39mmedian()\n\u001b[1;32m     20\u001b[0m t \u001b[39m=\u001b[39m df[df\u001b[39m.\u001b[39mAVG_MATH_8_SCORE\u001b[39m.\u001b[39misna()][[\u001b[39m'\u001b[39m\u001b[39mSTATE\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mAVG_MATH_8_SCORE\u001b[39m\u001b[39m'\u001b[39m]]\n\u001b[0;32m---> 21\u001b[0m t[\u001b[39m'\u001b[39;49m\u001b[39mAVG_MATH_8_SCORE\u001b[39;49m\u001b[39m'\u001b[39;49m] \u001b[39m=\u001b[39m s_m[t[\u001b[39m'\u001b[39m\u001b[39mSTATE\u001b[39m\u001b[39m'\u001b[39m]]\n\u001b[1;32m     22\u001b[0m t\n\u001b[1;32m     24\u001b[0m \u001b[39m# df.groupby(['STATE']).AVG_MATH_8_SCORE.median()\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \n\u001b[1;32m     26\u001b[0m \u001b[39m# df.AVG_MATH_8_SCORE.fillna(df.AVG_MATH_8_SCORE.groupby(['STATE']).median())\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[39m# df.AVG_READING_4_SCORE = df.AVG_READING_4_SCORE.fillna(df.AVG_READING_4_SCORE.median())\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[39m# df.AVG_READING_8_SCORE = df.AVG_READING_8_SCORE.fillna(df.AVG_READING_8_SCORE.median())\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pandas/core/frame.py:3978\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3975\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_setitem_array([key], value)\n\u001b[1;32m   3976\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   3977\u001b[0m     \u001b[39m# set column\u001b[39;00m\n\u001b[0;32m-> 3978\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_set_item(key, value)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pandas/core/frame.py:4172\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4162\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_set_item\u001b[39m(\u001b[39mself\u001b[39m, key, value) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   4163\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   4164\u001b[0m \u001b[39m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[1;32m   4165\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4170\u001b[0m \u001b[39m    ensure homogeneity.\u001b[39;00m\n\u001b[1;32m   4171\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4172\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sanitize_column(value)\n\u001b[1;32m   4174\u001b[0m     \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   4175\u001b[0m         key \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\n\u001b[1;32m   4176\u001b[0m         \u001b[39mand\u001b[39;00m value\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   4177\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_extension_array_dtype(value)\n\u001b[1;32m   4178\u001b[0m     ):\n\u001b[1;32m   4179\u001b[0m         \u001b[39m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[1;32m   4180\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mis_unique \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns, MultiIndex):\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pandas/core/frame.py:4909\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   4907\u001b[0m     \u001b[39mreturn\u001b[39;00m _reindex_for_setitem(value, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex)\n\u001b[1;32m   4908\u001b[0m \u001b[39melif\u001b[39;00m is_dict_like(value):\n\u001b[0;32m-> 4909\u001b[0m     \u001b[39mreturn\u001b[39;00m _reindex_for_setitem(Series(value), \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex)\n\u001b[1;32m   4911\u001b[0m \u001b[39mif\u001b[39;00m is_list_like(value):\n\u001b[1;32m   4912\u001b[0m     com\u001b[39m.\u001b[39mrequire_length_match(value, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pandas/core/frame.py:12022\u001b[0m, in \u001b[0;36m_reindex_for_setitem\u001b[0;34m(value, index)\u001b[0m\n\u001b[1;32m  12018\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m  12019\u001b[0m     \u001b[39m# raised in MultiIndex.from_tuples, see test_insert_error_msmgs\u001b[39;00m\n\u001b[1;32m  12020\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m value\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39mis_unique:\n\u001b[1;32m  12021\u001b[0m         \u001b[39m# duplicate axis\u001b[39;00m\n\u001b[0;32m> 12022\u001b[0m         \u001b[39mraise\u001b[39;00m err\n\u001b[1;32m  12024\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m  12025\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mincompatible index of inserted column with frame index\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m  12026\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m  12027\u001b[0m \u001b[39mreturn\u001b[39;00m reindexed_value\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pandas/core/frame.py:12017\u001b[0m, in \u001b[0;36m_reindex_for_setitem\u001b[0;34m(value, index)\u001b[0m\n\u001b[1;32m  12015\u001b[0m \u001b[39m# GH#4107\u001b[39;00m\n\u001b[1;32m  12016\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m> 12017\u001b[0m     reindexed_value \u001b[39m=\u001b[39m value\u001b[39m.\u001b[39;49mreindex(index)\u001b[39m.\u001b[39m_values\n\u001b[1;32m  12018\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m  12019\u001b[0m     \u001b[39m# raised in MultiIndex.from_tuples, see test_insert_error_msmgs\u001b[39;00m\n\u001b[1;32m  12020\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m value\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39mis_unique:\n\u001b[1;32m  12021\u001b[0m         \u001b[39m# duplicate axis\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pandas/core/series.py:5094\u001b[0m, in \u001b[0;36mSeries.reindex\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   5090\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m   5091\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mindex\u001b[39m\u001b[39m'\u001b[39m\u001b[39m passed as both positional and keyword argument\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   5092\u001b[0m         )\n\u001b[1;32m   5093\u001b[0m     kwargs\u001b[39m.\u001b[39mupdate({\u001b[39m\"\u001b[39m\u001b[39mindex\u001b[39m\u001b[39m\"\u001b[39m: index})\n\u001b[0;32m-> 5094\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mreindex(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pandas/core/generic.py:5289\u001b[0m, in \u001b[0;36mNDFrame.reindex\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   5286\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_multi(axes, copy, fill_value)\n\u001b[1;32m   5288\u001b[0m \u001b[39m# perform the reindex on the axes\u001b[39;00m\n\u001b[0;32m-> 5289\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_reindex_axes(\n\u001b[1;32m   5290\u001b[0m     axes, level, limit, tolerance, method, fill_value, copy\n\u001b[1;32m   5291\u001b[0m )\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mreindex\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pandas/core/generic.py:5309\u001b[0m, in \u001b[0;36mNDFrame._reindex_axes\u001b[0;34m(self, axes, level, limit, tolerance, method, fill_value, copy)\u001b[0m\n\u001b[1;32m   5304\u001b[0m new_index, indexer \u001b[39m=\u001b[39m ax\u001b[39m.\u001b[39mreindex(\n\u001b[1;32m   5305\u001b[0m     labels, level\u001b[39m=\u001b[39mlevel, limit\u001b[39m=\u001b[39mlimit, tolerance\u001b[39m=\u001b[39mtolerance, method\u001b[39m=\u001b[39mmethod\n\u001b[1;32m   5306\u001b[0m )\n\u001b[1;32m   5308\u001b[0m axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_axis_number(a)\n\u001b[0;32m-> 5309\u001b[0m obj \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39;49m_reindex_with_indexers(\n\u001b[1;32m   5310\u001b[0m     {axis: [new_index, indexer]},\n\u001b[1;32m   5311\u001b[0m     fill_value\u001b[39m=\u001b[39;49mfill_value,\n\u001b[1;32m   5312\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[1;32m   5313\u001b[0m     allow_dups\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m   5314\u001b[0m )\n\u001b[1;32m   5315\u001b[0m \u001b[39m# If we've made a copy once, no need to make another one\u001b[39;00m\n\u001b[1;32m   5316\u001b[0m copy \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pandas/core/generic.py:5355\u001b[0m, in \u001b[0;36mNDFrame._reindex_with_indexers\u001b[0;34m(self, reindexers, fill_value, copy, allow_dups)\u001b[0m\n\u001b[1;32m   5352\u001b[0m     indexer \u001b[39m=\u001b[39m ensure_platform_int(indexer)\n\u001b[1;32m   5354\u001b[0m \u001b[39m# TODO: speed up on homogeneous DataFrame objects (see _reindex_multi)\u001b[39;00m\n\u001b[0;32m-> 5355\u001b[0m new_data \u001b[39m=\u001b[39m new_data\u001b[39m.\u001b[39;49mreindex_indexer(\n\u001b[1;32m   5356\u001b[0m     index,\n\u001b[1;32m   5357\u001b[0m     indexer,\n\u001b[1;32m   5358\u001b[0m     axis\u001b[39m=\u001b[39;49mbaxis,\n\u001b[1;32m   5359\u001b[0m     fill_value\u001b[39m=\u001b[39;49mfill_value,\n\u001b[1;32m   5360\u001b[0m     allow_dups\u001b[39m=\u001b[39;49mallow_dups,\n\u001b[1;32m   5361\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[1;32m   5362\u001b[0m )\n\u001b[1;32m   5363\u001b[0m \u001b[39m# If we've made a copy once, no need to make another one\u001b[39;00m\n\u001b[1;32m   5364\u001b[0m copy \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pandas/core/internals/managers.py:739\u001b[0m, in \u001b[0;36mBaseBlockManager.reindex_indexer\u001b[0;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy, only_slice, use_na_proxy)\u001b[0m\n\u001b[1;32m    737\u001b[0m \u001b[39m# some axes don't allow reindexing with dups\u001b[39;00m\n\u001b[1;32m    738\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m allow_dups:\n\u001b[0;32m--> 739\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maxes[axis]\u001b[39m.\u001b[39;49m_validate_can_reindex(indexer)\n\u001b[1;32m    741\u001b[0m \u001b[39mif\u001b[39;00m axis \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mndim:\n\u001b[1;32m    742\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIndexError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mRequested axis not found in manager\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pandas/core/indexes/base.py:4359\u001b[0m, in \u001b[0;36mIndex._validate_can_reindex\u001b[0;34m(self, indexer)\u001b[0m\n\u001b[1;32m   4357\u001b[0m \u001b[39m# trying to reindex on an axis with duplicates\u001b[39;00m\n\u001b[1;32m   4358\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_as_unique \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(indexer):\n\u001b[0;32m-> 4359\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mcannot reindex on an axis with duplicate labels\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reindex on an axis with duplicate labels"
     ]
    }
   ],
   "source": [
    "df.rename({\n",
    "    'GRADES_PK_G':'ENROLL_PREK',\n",
    "    'GRADES_KG_G':'ENROLL_KINDER',\n",
    "    'GRADES_4_G':'ENROLL_4',\n",
    "    'GRADES_8_G':'ENROLL_8',\n",
    "    'GRADES_12_G':'ENROLL_12',\n",
    "    'GRADES_1_8_G':'ENROLL_PRIMARY',\n",
    "    'GRADES_9_12_G':'ENROLL_HS',\n",
    "    'GRADES_ALL_G':'ENROLL_ALL',\n",
    "    'ENROLL':'ENROLL_ALL_EST'\n",
    "    },\n",
    "    axis=1,inplace=True)\n",
    "\n",
    "df.ENROLL_ALL_EST = df.ENROLL_ALL_EST.fillna(df.ENROLL_ALL)\n",
    "df.ENROLL_ALL_EST.dropna(inplace=True)\n",
    "\n",
    "\n",
    "# df.groupby(['STATE']).AVG_MATH_8_SCORE.median()\n",
    "s_m = df.groupby(['STATE']).AVG_MATH_8_SCORE.median()\n",
    "t = df[df.AVG_MATH_8_SCORE.isna()][['STATE', 'AVG_MATH_8_SCORE']]\n",
    "t['AVG_MATH_8_SCORE'] = s_m\n",
    "t\n",
    "\n",
    "# df.groupby(['STATE']).AVG_MATH_8_SCORE.median()\n",
    "\n",
    "# df.AVG_MATH_8_SCORE.fillna(df.AVG_MATH_8_SCORE.groupby(['STATE']).median())\n",
    "\n",
    "# df.AVG_MATH_8_SCORE = df.AVG_MATH_8_SCORE.fillna(df.AVG_MATH_8_SCORE.median())\n",
    "# df.AVG_MATH_4_SCORE = df.AVG_MATH_4_SCORE.fillna(df.AVG_MATH_4_SCORE.median())\n",
    "# df.AVG_READING_4_SCORE = df.AVG_READING_4_SCORE.fillna(df.AVG_READING_4_SCORE.median())\n",
    "# df.AVG_READING_8_SCORE = df.AVG_READING_8_SCORE.fillna(df.AVG_READING_8_SCORE.median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Exploratory Data Analysis (EDA) </h2>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chosen Outcome Variable for Test: AVG_MATH_8_SCORE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many years of data are logged in our dataset? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.YEAR.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare Michigan to Ohio. Which state has the higher average outcome score across all years?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MI AVG_MATH_8_SCORE: 278.92424242424244\n",
      "OH AVG_MATH_8_SCORE: 281.1363636363636\n"
     ]
    }
   ],
   "source": [
    "print('MI AVG_MATH_8_SCORE: {}'.format(df[df[\"STATE\"] == 'MICHIGAN'].AVG_MATH_8_SCORE.mean()))\n",
    "print('OH AVG_MATH_8_SCORE: {}'.format(df[df[\"STATE\"] == 'OHIO'].AVG_MATH_8_SCORE.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the average for your outcome score across all states in 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "281.2641509433962"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['YEAR'] == 2019].AVG_MATH_8_SCORE.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the maximum outcome score for every state. \n",
    "\n",
    "Refer to the `Grouping and Aggregating` section in Tutorial 0 if you are stuck."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "STATE\n",
       "ALABAMA                 280.5\n",
       "ALASKA                  283.0\n",
       "ARIZONA                 283.0\n",
       "ARKANSAS                280.5\n",
       "CALIFORNIA              280.5\n",
       "COLORADO                292.0\n",
       "CONNECTICUT             289.0\n",
       "DELAWARE                284.0\n",
       "DISTRICT_OF_COLUMBIA    280.5\n",
       "DODEA                   293.0\n",
       "FLORIDA                 281.0\n",
       "GEORGIA                 281.0\n",
       "HAWAII                  281.0\n",
       "IDAHO                   287.0\n",
       "ILLINOIS                285.0\n",
       "INDIANA                 288.0\n",
       "IOWA                    286.0\n",
       "KANSAS                  290.0\n",
       "KENTUCKY                282.0\n",
       "LOUISIANA               280.5\n",
       "MAINE                   289.0\n",
       "MARYLAND                288.0\n",
       "MASSACHUSETTS           301.0\n",
       "MICHIGAN                280.5\n",
       "MINNESOTA               295.0\n",
       "MISSISSIPPI             280.5\n",
       "MISSOURI                286.0\n",
       "MONTANA                 293.0\n",
       "NATIONAL                285.0\n",
       "NEBRASKA                288.0\n",
       "NEVADA                  280.5\n",
       "NEW_HAMPSHIRE           296.0\n",
       "NEW_JERSEY              296.0\n",
       "NEW_MEXICO              280.5\n",
       "NEW_YORK                283.0\n",
       "NORTH_CAROLINA          286.0\n",
       "NORTH_DAKOTA            293.0\n",
       "OHIO                    290.0\n",
       "OKLAHOMA                280.5\n",
       "OREGON                  285.0\n",
       "PENNSYLVANIA            290.0\n",
       "RHODE_ISLAND            284.0\n",
       "SOUTH_CAROLINA          282.0\n",
       "SOUTH_DAKOTA            291.0\n",
       "TENNESSEE               280.5\n",
       "TEXAS                   290.0\n",
       "UTAH                    287.0\n",
       "VERMONT                 295.0\n",
       "VIRGINIA                290.0\n",
       "WASHINGTON              290.0\n",
       "WEST_VIRGINIA           280.5\n",
       "WISCONSIN               289.0\n",
       "WYOMING                 289.0\n",
       "Name: AVG_MATH_8_SCORE, dtype: float64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['STATE']).AVG_MATH_8_SCORE.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Feature Engineering </h2>\n",
    "\n",
    "After exploring the data, you can choose to modify features that you would use to predict the performance of the students on your chosen response variable. \n",
    "\n",
    "You can also create your own features. For example, perhaps you figured that maybe a state's expenditure per student may affect their overall academic performance so you create a expenditure_per_student feature.\n",
    "\n",
    "Use this space to modify or create features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature engineering justification: **<BRIEFLY DESCRIBE WHY YOU MADE THE CHANGES THAT YOU DID\\>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Visualization</h2>\n",
    "\n",
    "Investigate the relationship between your chosen response variable and at least two predictors using visualizations. Write down your observations.\n",
    "\n",
    "**Visualization 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<CAPTION FOR VIZ 1>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualization 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<CAPTION FOR VIZ 2>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Data Creation </h2>\n",
    "\n",
    "_Use this space to create train/test data_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X =\n",
    "# y = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#      X, y, test_size=, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Prediction </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ML Models [Resource](https://medium.com/@vijaya.beeravalli/comparison-of-machine-learning-classification-models-for-credit-card-default-data-c3cf805c9a5a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import your sklearn class here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create your model here\n",
    "# model = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose some metrics to evaluate the performance of your model, some of them are mentioned in the tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have copied over the graphs that visualize the model's performance on the training and testing set. \n",
    "\n",
    "Change `col_name` and modify the call to `plt.ylabel()` to isolate how a single predictor affects the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# col_name = 'COLUMN NAME OF ONE PREDICTOR'\n",
    "\n",
    "# f = plt.figure(figsize=(12,6))\n",
    "# plt.scatter(X_train[col_name], y_train, color = \"red\")\n",
    "# plt.scatter(X_train[col_name], model.predict(X_train), color = \"green\")\n",
    "\n",
    "# plt.legend(['True Training','Predicted Training'])\n",
    "# plt.xlabel(col_name)\n",
    "# plt.ylabel('NAME OF THE PREDICTOR')\n",
    "# plt.title(\"Model Behavior On Training Set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# col_name = 'COLUMN NAME OF ONE PREDICTOR\"\n",
    "\n",
    "# f = plt.figure(figsize=(12,6))\n",
    "# plt.scatter(X_test[col_name], y_test, color = \"blue\")\n",
    "# plt.scatter(X_test[col_name], model.predict(X_test), color = \"black\")\n",
    "\n",
    "# plt.legend(['True testing','Predicted testing'])\n",
    "# plt.xlabel(col_name)\n",
    "# plt.ylabel('NAME OF THE PREDICTOR')\n",
    "# plt.title(\"Model Behavior on Testing Set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Summary </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<WRITE A PARAGRAPH SUMMARIZING YOUR WORK, FINDINGS, AND THE PERFORMANCE OF YOUR MODEL\\>**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
